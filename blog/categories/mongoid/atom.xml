<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mongoid | Artsy Engineering]]></title>
  <link href="http://artsy.github.io/blog/categories/mongoid/atom.xml" rel="self"/>
  <link href="http://artsy.github.io/"/>
  <updated>2013-08-29T18:31:03-04:00</updated>
  <id>http://artsy.github.io/</id>
  <author>
    <name><![CDATA[Artsy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Adding API Docs with Grape and Swagger]]></title>
    <link href="http://artsy.github.io/blog/2013/06/21/adding-api-documentation-with-grape-swagger/"/>
    <updated>2013-06-21T12:21:00-04:00</updated>
    <id>http://artsy.github.io/blog/2013/06/21/adding-api-documentation-with-grape-swagger</id>
    <content type="html"><![CDATA[<p>The Artsy website, Partner CMS, mobile tools, and all our hackathon experiments are built on top of a core API. We've put a lot of effort into documenting it internally. But developers don't want to have to grok through code. With <a href="https://github.com/intridea/grape">Grape</a> and <a href="https://developers.helloreverb.com/swagger">Swagger</a>, adding an API explorer and exposing the API documentation has never been easier.</p>

<p><img src="http://artsy.github.io/images/2013-06-21-adding-api-documentation-with-grape-swagger/swagger-ui.png" /></p>

<!-- more -->


<h3>Cross Origin Requests</h3>

<p>You don't need to include the API explorer into your application. Instead, enable Cross-Origin Resource Sharing (CORS) with <a href="https://github.com/cyu/rack-cors">rack-cors</a>.</p>

<p><code>ruby Gemfile
gem "rack-cors"
</code></p>

<p>``` ruby app.rb
use Rack::Cors do
  allow do</p>

<pre><code>origins '*'
resource '*', headers: :any, methods: :get
</code></pre>

<p>  end
end
```</p>

<p>Your application will now respond to <code>OPTIONS</code> and <code>GET</code> requests with CORS headers. It's also important to verify that errors still contain CORS headers, as shown in these RSpec tests.</p>

<p>``` ruby spec/cors_spec.rb
context "CORS" do
  it "supports options" do</p>

<pre><code>options "/", {}, {
  "HTTP_ORIGIN" =&gt; "http://cors.example.com",
  "HTTP_ACCESS_CONTROL_REQUEST_HEADERS" =&gt; "Origin, Accept, Content-Type",
  "HTTP_ACCESS_CONTROL_REQUEST_METHOD" =&gt; "GET"
}
last_response.status.should == 200
last_response.headers['Access-Control-Allow-Origin'].should == "http://cors.example.com"
last_response.headers['Access-Control-Expose-Headers'].should == ""
</code></pre>

<p>  end
  it "includes Access-Control-Allow-Origin in the response" do</p>

<pre><code>get "/", {}, "HTTP_ORIGIN" =&gt; "http://cors.example.com"
last_response.status.should == 200
last_response.headers['Access-Control-Allow-Origin'].should == "http://cors.example.com"
</code></pre>

<p>  end
  it "includes Access-Control-Allow-Origin in errors" do</p>

<pre><code>get "/invalid", {}, "HTTP_ORIGIN" =&gt; "http://cors.example.com"
last_response.status.should == 404
last_response.headers['Access-Control-Allow-Origin'].should == "http://cors.example.com"
</code></pre>

<p>  end
end
```</p>

<h3>Grape-Swagger</h3>

<p>There's a gem called <a href="https://github.com/tim-vandecasteele/grape-swagger">grape-swagger</a> that exposes Swagger-compatible documentation from any Grape API with a one-liner, <code>add_swagger_documentation</code>.</p>

<p>``` ruby api.rb
module Acme
  class API &lt; Grape::API</p>

<pre><code>format :json

desc "This is the root of our API."
get "/" do

end

add_swagger_documentation api_version: 'v1'
</code></pre>

<p>  end
end
```</p>

<p><code>ruby spec/documentation_spec.rb
it "swagger documentation" do
  get "/api/swagger_doc"
  last_response.status.should == 200
  json_response = JSON.parse(last_response.body)
  json_response["apiVersion"].should == "v1"
  json_response["apis"].size.should &gt; 0
end
</code></p>

<h3>Swagger UI</h3>

<p>Use the <a href="http://petstore.swagger.wordnik.com">Swagger Petstore</a>, start your application, enter <em>http://localhost:9292/api/swagger_doc</em> and explore your API!</p>

<p><img src="http://artsy.github.io/images/2013-06-21-adding-api-documentation-with-grape-swagger/swagger-ping.png" /></p>

<h3>Working Sample</h3>

<p>You can find a working sample in <a href="https://github.com/dblock/grape-on-rack">this demo application</a>, added in <a href="https://github.com/dblock/grape-on-rack/commit/004670804472812322b089fcf6a40b33d68c699c">this commit</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Infinite Scroll with MongoDB]]></title>
    <link href="http://artsy.github.io/blog/2013/02/15/infinite-scroll-with-mongodb/"/>
    <updated>2013-02-15T21:21:00-05:00</updated>
    <id>http://artsy.github.io/blog/2013/02/15/infinite-scroll-with-mongodb</id>
    <content type="html"><![CDATA[<p>An infinite scroll can be a beautiful and functional way to present feed data. You can see ours on the <a href="http://artsy.net/">homepage of artsy.net</a>. It works by fetching a few items from the API, then fetching some more items as the user scrolls down the feed. Each API call returns the items along with a "cursor", which marks the position of the last item retrieved. Subsequent API calls include the cursor in the query string and the iteration resumes from there.</p>

<p>Why use a cursor and not standard pagination? Because inserting an item on top of the feed would shift the existing items down, causing the API to return a duplicate item on the page boundary. Removing an item from the top of the feed would pull the remaining items up, causing an item to be missed in the next request on the page boundary.</p>

<p>Today we're open-sourcing a small gem called <a href="https://github.com/dblock/mongoid-scroll">mongoid-scroll</a>, which implements this cursor-like behavior for MongoDB using mongoid or moped. Here's how it works.</p>

<!-- more -->


<h2>Example</h2>

<p>Define a sample <code>FeedItem</code> model with an index on <code>position</code>. We'll be iterating over our feed, starting with the newest item first.</p>

<p>```ruby
module Feed
  class Item</p>

<pre><code>include Mongoid::Document
field :title, type: String
field :position, type: Integer
index({ position: -1, _id: 1 })
</code></pre>

<p>  end
end
```</p>

<p>Insert some sample unordered data manufactured with <a href="https://github.com/stympy/faker">faker</a>.</p>

<p><code>ruby
total_items = 20
rands = (0..total_items).to_a.sort { rand }[0..total_items]
total_items.times do |i|
  Feed::Item.create! title: Faker::Lorem.sentence, position: rands.pop + 1
end
</code></p>

<p>Iterate over this collection using a cursor, 7 items at a time.</p>

<p>```ruby
next_cursor = nil
while true
  current_cursor = next_cursor
  next_cursor = nil
  Feed::Item.desc(:position).limit(7).scroll(current_cursor) do |item, cursor|</p>

<pre><code>puts "#{item.position}: #{item.title}"
next_cursor = cursor
</code></pre>

<p>  end
  break unless next_cursor
  # destroy an item, the scroll is not affected
  Feed::Item.desc(:position).first.destroy
end
```</p>

<p>The result is, as expected, all 20 items in reverse order.</p>

<p><code>text
20: Quae eveniet est a.
19: Ab voluptatem aut possimus.
18: Tenetur voluptatem aut modi eos et fugiat ipsa impedit.
17: Autem enim qui illum ut sed et et pariatur.
16: Est molestias quidem adipisci culpa non.
15: Incidunt ad atque minus fuga illum ex earum.
14: Ullam et cum harum tempore nostrum consequatur.
13: Porro nostrum laboriosam aperiam blanditiis est.
12: Facere non a vel est sapiente sit officiis.
11: Itaque commodi deserunt aut exercitationem aut voluptatem.
10: Veritatis mollitia libero hic velit quos.
9: Iste ea dicta ut culpa.
8: Voluptatibus vel et minima.
7: Possimus molestiae quis consectetur iusto sed.
6: Aut fugit omnis incidunt.
5: Recusandae corrupti est in dolor est commodi aut.
4: Tenetur veniam ut id.
3: Voluptas exercitationem eos quia rem quia quas qui quae.
2: Eveniet repellendus corrupti molestiae molestias qui ullam.
1: Sapiente impedit iste quos eligendi cupiditate accusantium ad.
</code></p>

<p>We've used 4 queries to iterate over this collection.</p>

<h2>First Query</h2>

<p>The first ordered query without an existing cursor uses a <code>limit</code>.</p>

<p><code>javascript
db.feed_items.find().sort({ position: -1, _id: -1 }).limit(7)
</code></p>

<p>The last item returned has a position of 14 (we scrolled from 20 down to 14, including the boundaries).</p>

<h2>Second and Third Query</h2>

<p>The second ordered query has to fetch any item that comes after 14, including any other item that has the same position further in the same direction as the MongoDB order (there're no duplicates in our example, but it's entirely possible).</p>

<p><code>javascript
db.feed_items.find({ "$or" : [
 { "position" : { "$lt" : 14 }},
 { "position" : 14, "_id": { "$lt" : ObjectId("511d7c7c3b5552c92400000e") }}
]}).sort({ position: -1, _id: -1 }).limit(7)
</code></p>

<p>Note that we're sorting by <code>_id</code> as well because MongoDB may relocate a document and therefore alter the natural order. See <a href="https://github.com/dblock/mongoid-scroll/commit/3cd75ded93f82adfcb1c17a8b9c98715c536b680">this commit</a> for a test that reproduces this behavior.</p>

<h2>Last Query</h2>

<p>We've chosen to break out of the loop after getting no data back in the 4th iteration. You can check whether the item retrieved is the last one in the collection as an alternative to prevent this fourth empty database query.</p>

<h2>Cursors</h2>

<p>Cursors consist of the item's position and the item's BSON id. The cursor for the item at position 14 is <code>14:511d7c7c3b5552c92400000e</code>. This cursor is parsed to construct the query on subsequent requests or can be supplied as a <code>Mongoid::Scroll::Cursor</code> object.</p>

<h2>Links</h2>

<ul>
<li><a href="https://github.com/dblock/mongoid-scroll">mongoid-scroll on Github</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data Corruption and Concurrent Updates to Embedded Objects with MongoDB]]></title>
    <link href="http://artsy.github.io/blog/2013/02/09/data-corruption-and-concurrent-updates-to-embedded-objects-with-mongoid/"/>
    <updated>2013-02-09T21:21:00-05:00</updated>
    <id>http://artsy.github.io/blog/2013/02/09/data-corruption-and-concurrent-updates-to-embedded-objects-with-mongoid</id>
    <content type="html"><![CDATA[<p>We use <a href="http://www.mongodb.org/">MongoDB</a> at Artsy as our primary data store via the <a href="http://mongoid.org/">Mongoid ODM</a>. Eventually, we started noticing data corruption inside embedded objects at an alarming rate of 2-3 records a day. The number of occurrences increased rapidly with load as our user growth accelerated.</p>

<p>The root cause was not a HN-worthy sensational declaration about how MongoDB trashes data, but our lack of understanding of what can and cannot be concurrently written to the database, neatly hidden behind the object data mapping layer.</p>

<!-- more -->


<h3>Data Model</h3>

<p>Consider the following artwork model with embedded images.</p>

<p>```ruby
class Artwork
  include Mongoid::Document
  field :title, type: String
  embeds_many :images
end</p>

<p>class Image
  include Mongoid::Document
  embedded_in :artwork
  field :filename, type: String
  field :width, type: Integer<br/>
  field :height, type: Integer
end
```</p>

<p>Let's create a few objects and examine the database queries executed when constructing this relationship by setting a <code>DEBUG</code> logger level on the Moped driver used underneath the ODM.</p>

<p>```ruby
Moped.logger = Logger.new($stdout)
Moped.logger.level = Logger::DEBUG</p>

<h1>db.artworks.insert({</h1>

<h1>_id: ObjectId("510f22c5db8e540aab000001"),</h1>

<h1>title: "Mona Lisa"</h1>

<h1>})</h1>

<p>artwork = Artwork.create!(title: "Mona Lisa")</p>

<p>image1 = Image.new(filename: "framed.jpg")</p>

<h1>db.artworks.update(</h1>

<h1>{ _id: ObjectId("510f22c5db8e540aab000001") },</h1>

<h1>{ $push :</h1>

<h1>{ images:</h1>

<h1>{</h1>

<h1>_id: ObjectId("510f22c5db8e540aab000002"),</h1>

<h1>filename: "framed.jpg"</h1>

<h1>}</h1>

<h1>}</h1>

<h1>}</h1>

<h1>)</h1>

<p>artwork.images &lt;&lt; image1</p>

<p>image2 = Image.new(filename: "unframed.jpg")</p>

<h1>db.artworks.update(</h1>

<h1>{ _id: ObjectId("510f22c5db8e540aab000001") },</h1>

<h1>{ $push :</h1>

<h1>{ images:</h1>

<h1>{</h1>

<h1>_id: ObjectId("510f22c5db8e540aab000003"),</h1>

<h1>filename: "unframed.jpg"</h1>

<h1>}</h1>

<h1>}</h1>

<h1>}</h1>

<h1>)</h1>

<p>artwork.images &lt;&lt; image2
```</p>

<p>Here's the artwork data in MongoDB retrieved from a <code>mongo</code> shell:</p>

<p>```</p>

<blockquote><p>db.artworks.findOne()
{
  "_id" : ObjectId("510f22c5db8e540aab000001"),
  "title" : "Mona Lisa",
  "images" : [</p>

<pre><code>{
  "_id" : ObjectId("510f22c5db8e540aab000002"),
  "filename" : "framed.jpg"
},
{
  "_id" : ObjectId("510f22c5db8e540aab000003"),
  "filename" : "unframed.jpg"
}
</code></pre>

<p>  ]
}
```</p></blockquote>

<p>We can modify the attributes of the second image.</p>

<p>```ruby</p>

<h1>db.artworks.update(</h1>

<h1>{ _id: ObjectId("510f22c5db8e540aab000001") },</h1>

<h1>{ $set : { "images.1.width" : 30, "images.1.height" : 40 } }</h1>

<h1>)</h1>

<p>image2.update_attributes!(width: 30, height: 40)
```</p>

<p>The image has been updated correctly.</p>

<p>```</p>

<blockquote><p>db.artworks.findOne()
{
  "_id" : ObjectId("510f22c5db8e540aab000001"),
  "title" : "Mona Lisa",
  "images" : [</p>

<pre><code>{
  "_id" : ObjectId("510f22c5db8e540aab000002"),
  "filename" : "framed.jpg"
},
{
  "_id" : ObjectId("510f22c5db8e540aab000003"),
  "filename" : "unframed.jpg",
  "height" : 40,
  "width" : 30
}
</code></pre>

<p>  ]
}
```</p></blockquote>

<h3>Incomplete Record Corruption</h3>

<p>Examining the query you will notice that it uses a so-called "positional" operator, <code>images.1.width</code> to update the second record. Imagine what would happen if the first record was deleted from another process immediately before the update. That's right, the update will be performed on a record that doesn't exist, in which case the default MongoDB behavior is to create it!</p>

<p>We can simulate this by loading the object in Ruby, pulling the first record directly from the database and then performing the update.</p>

<p>```ruby
artwork.images &lt;&lt; image2</p>

<h1>pull the first artwork directly from the database</h1>

<p>Artwork.collection.where(<em>id: artwork.id).update(
  "$pull" => { "images" => { </em>id: image1.id } })</p>

<p>image2.update_attributes!(width: 30, height: 40)
```</p>

<p>This yields a nasty surprise. We now have two records in the embedded collection, the second one missing an <code>_id</code>.</p>

<p>```</p>

<blockquote><p>db.artworks.findOne()
{
  "_id" : ObjectId("510f22c5db8e540aab000001"),
  "title" : "Mona Lisa",
  "images" : [</p>

<pre><code>{
  "_id" : ObjectId("510f22c5db8e540aab000003"),
  "filename" : "unframed.jpg"
},
{
  "height" : 40,
  "width" : 30
}
</code></pre>

<p>  ]
}
```</p></blockquote>

<p>When reloaded, Mongoid will assign an automatic <code>_id</code> to the second object, the correct height and width, but no filename.</p>

<h3>Null Record Corruption</h3>

<p>A similar scenario can play out by pulling both image records out of the embedded collection and making a positional update. This will create a <code>null</code> record, which is much worse, because Mongoid can't even destroy it, attempting to pull a record with an <code>_id</code> that does not exist.</p>

<p>```ruby
artwork.images &lt;&lt; image2</p>

<p>Artwork.collection.where(<em>id: artwork.id).update(
  "$pull" => { "images" => { </em>id: image1.id } })
Artwork.collection.where(<em>id: artwork.id).update(
  "$pull" => { "images" => { </em>id: image2.id } })</p>

<p>image2.update_attributes!(width: 30, height: 40)
```</p>

<p>```</p>

<blockquote><p>db.artworks.findOne()
{
  "_id" : ObjectId("510f22c5db8e540aab000001"),
  "title" : "Mona Lisa"
  "images" : [</p>

<pre><code>null,
{
  "height" : 40,
  "width" : 30
}
</code></pre>

<p>  ],
}
```</p></blockquote>

<h3>Solutions</h3>

<p>A first obvious solution is not to use embedded objects or to never modify them. Both <code>$push</code> and <code>$pull</code> are atomic operations, but not the positional update.</p>

<p>A general solution to this problem is to make all update operations transactional. You can take a lock on the parent model by using <a href="https://github.com/afeld/mongoid-locker">mongoid-locker</a>. It works, but can be quite tedious depending on the complexity of your application.</p>

<p>Finally, MongoDB supports something called a "positional operator" for embedded objects. This means you can atomically update a record found by its embedded object's field using a reference to the position of that embedded object. This solves our problem, as long as the object is not embedded below the first level. Mongoid 3.1 (currently HEAD) implements this behavior by default (see <a href="https://github.com/mongoid/mongoid/issues/2545">#2545</a> for details), adjusting the selector to look for the embedded object's <code>_id</code> and replacing the position with a <code>$</code> positional operator.</p>

<p>```ruby</p>

<h1>db.artworks.update(</h1>

<h1>{</h1>

<h1>_id: ObjectId("510f22c5db8e540aab000001"),</h1>

<h1>"images._id" : ObjectId("510f22c5db8e540aab000003")</h1>

<h1>},</h1>

<h1>{ $set : { "images.$.width" : 30, "images.$.height" : 40 }}</h1>

<h1>)</h1>

<p>image2.update_attributes!(width: 30, height: 40)
```</p>

<p>We've been successfully running this in production for a few weeks now, without any more data corruption issues.</p>

<p>While this is a huge step forward, covering all of our application's scenarios, we would like complete native support for atomic updates inside MongoDB at all levels of nesting. Please add your +1 to <a href="https://jira.mongodb.org/browse/SERVER-831">SERVER-831</a>.</p>

<h3>Links</h3>

<ul>
<li><a href="https://gist.github.com/dblock/4699070">Code to Detect Corrupt Embedded Objects</a></li>
<li><a href="https://jira.mongodb.org/browse/SERVER-831">MongoDB SERVER-831: Positional Operator Matching Nested Arrays</a></li>
<li><a href="https://github.com/mongoid/mongoid/issues/2545">Mongoid #2545: Use $ Positional Operator for Updating Embedded Documents</a></li>
<li><a href="https://github.com/dblock/mongoid/tree/master-issues/spec/dblock">Repro Specs for Mongoid #2545 and Similar</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Create MongoDB Command-Lines from Mongoid Configuration]]></title>
    <link href="http://artsy.github.io/blog/2013/01/31/create-mongodb-command-lines-with-mongo/"/>
    <updated>2013-01-31T21:21:00-05:00</updated>
    <id>http://artsy.github.io/blog/2013/01/31/create-mongodb-command-lines-with-mongo</id>
    <content type="html"><![CDATA[<p>We use MongoDB as our primary store and have built a healthy amount of automation around various database instances and operational environments. For example, we backup databases to S3 using <code>mongodump</code>, mirror data between instances with <code>mongorestore</code> and often need to open a MongoDB shell with <code>mongo</code> to examine data at the lowest level.</p>

<p>Generating MongoDB command-lines is tedious and error-prone. Introducing a new gem called <a href="https://github.com/dblock/mongoid-shell">mongoid-shell</a> to help with this. The library can generate command-lines for various MongoDB shell tools from your Mongoid configuration.</p>

<p>For example, connect to your production MongoDB instance from a <code>db:production:shell</code> Rake task.</p>

<p>```ruby
namespace :db
  namespace :production</p>

<pre><code>task :shell
  Mongoid.load! "mongoid.yml", :production
  system Mongoid::Shell::Commands::Mongo.new.to_s
end
</code></pre>

<p>  end
end
```</p>

<!-- more -->


<p>Commands can be created for the current default session or you can pass a session as an argument to a new command.</p>

<p>```ruby</p>

<h1>will use Mongoid.default_session</h1>

<p>Mongoid::Shell::Commands::Mongodump.new</p>

<h1>use a hand-crafted session</h1>

<p>s = Moped::Session.new([ "127.0.0.1:27017" ])
Mongoid::Shell::Commands::Mongodump.new(session: s)
```</p>

<p>Commands accept parameters. Here's how to backup <code>my_database</code> to <code>/tmp/db_backup</code>.</p>

<p>```ruby
out = File.join(Dir.tmpdir, 'db_backup')
db = 'my_database'
dump = Mongoid::Shell::Commands::Mongodump.new(db: db, out: out)</p>

<h1>mongodump --db my_database --out /tmp/db_backup</h1>

<p>system dump.to_s
```</p>

<p>The mongoid-shell gem currently supports <code>mongo</code>, <code>mongodump</code>, <code>mongorestore</code> and <code>mongostat</code> and various MongoDB configurations, including replica-sets.</p>

<p>Please note that we don't recommend you store passwords for production environments in your <code>mongoid.yml</code>. At Artsy, we set all sensitive values directly on our Heroku instances with <code>heroku config:add</code> and use <a href="https://github.com/dblock/heroku-commander">heroku-commander</a> to retrieve these settings in rake. We also have a bit of convention in our application name, such as "app-staging" and "app-production".</p>

<p>Here's a complete Rake task that dynamically fetches Heroku configuration and opens a MongoDB shell on a production or staging environment.</p>

<p>```ruby
namespace :db do
  [ :staging, :production ].each do |env|</p>

<pre><code>namespace env do
  task :shell do
    app = "myapp-#{env}"
    config = Heroku::Commander.new(app: app).config
    config.each_pair do |k, v|
      ENV[k] = v
    end
    mongoid_yml = File.join(Rails.root, "config/mongoid.yml")
    Mongoid.load! mongoid_yml, env
    system Mongoid::Shell::Commands::Mongo.new.to_s
  end
end
</code></pre>

<p>  end
end
```</p>

<p>Run <code>rake db:staging:shell</code> or <code>rake db:production:shell</code>, which works as long as you have access to the Heroku app itself. A bonus feature is that the mongoid-shell gem will automatically connect to the primary node of a replica-set.</p>

<p>```
$ rake db:staging:shell
 mongo db:10007/app-staging --username user --password ************
 MongoDB shell version: 2.0.7
 connecting to: db:10007/app-staging</p>

<blockquote><p>```</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving Performance of Mongoid-Cached-Json]]></title>
    <link href="http://artsy.github.io/blog/2013/01/20/improving-performance-of-mongoid-cached-json/"/>
    <updated>2013-01-20T21:21:00-05:00</updated>
    <id>http://artsy.github.io/blog/2013/01/20/improving-performance-of-mongoid-cached-json</id>
    <content type="html"><![CDATA[<p>Last year, we have open-sourced and made extensive use of two Ruby libraries in our API: <a href="https://github.com/dblock/mongoid-cached-json">mongoid-cached-json</a> and <a href="https://github.com/artsy/garner">garner</a>. Both transform the procedural nightmare of caching and JSON generation into a declarative and easily manageable DSL. It was worth the investment, since our service spends half of its time generating JSON and reading from and writing to Memcached.</p>

<p>Today we've released mongoid-cached-json 1.4 with two interesting performance improvements.</p>

<!-- more -->


<h2>Bulk Reference Resolving with a Local Cache</h2>

<p>Consider an array of database model instances, each with numerous references to other objects. It's typical to see such instances reference the same object: for example we have an <code>Artwork</code> that references an <code>Artist</code>. It's common to see multiple artworks reference the same artist in a collection. Retrieving the artist from cache every time it is referenced is clearly inefficient.</p>

<p><code>Mongoid::CachedJson</code> will now collect all JSON references, then resolve them after suppressing duplicates, in-place within the JSON tree. This significantly reduces the number of cache queries.</p>

<p>Note, that while this optimization reduces load on the Memcached servers, there's a cost of doing additional work after collecting the entire JSON in Ruby.</p>

<h2>Fetching Cache Data in Bulk</h2>

<p>Various cache stores, including Memcached, support bulk read operations. The <a href="https://github.com/mperham/dalli">Dalli</a> gem, which we use in production, exposes this via the <code>read_multi</code> method. With the bulk reference optimization above we now have the entire list of keys to query from cache, at once. <code>Mongoid::CachedJson</code> will always invoke <code>read_multi</code> where available, which significantly reduces the number of network roundtrips to the cache servers.</p>

<p>This is a good example of where declarative models and DSLs have tremendous advantages in enabling massive improvements across the board. Imagine making the <code>read_multi</code> optimization in hundreds of API endpoints!</p>

<h2>Benchmarks</h2>

<p>With the above optimizations the library does more work in order to make less roundtrips to Memcached over the network. Since the network is often the slowest part in any large scale system, the overall production performance should be better as long as we can obtain similar throughput in ideal network conditions on localhost. We've added some common case benchmarks in <a href="https://github.com/dblock/mongoid-cached-json/blob/master/spec/benchmark_spec.rb">spec/benchmark_spec.rb</a> and ran them against 1.2.3 and 1.4.0 to obtain <a href="https://gist.github.com/4583039">these results</a>. The overall performance gain averaged 14.6%, which is quite significant. With real world data in a production environment we're seeing 15-50% less time spent in Memcached, depending on the API.</p>

<h2>Links</h2>

<p>The concepts behind these improvements should be attributed to <a href="https://github.com/aaw">@aaw</a> and <a href="https://github.com/macreery">@macreery</a>. If you want to learn more about the above-mentioned libraries, check out the following links:</p>

<ul>
<li><a href="http://confreaks.com/videos/986-goruco2012-from-zero-to-api-cache-w-grape-mongodb-in-10-minutes">From Zero to API-Cache w/ Grape and MongoDB</a>, video recorded at GoRuCo</li>
<li><a href="/blog/2012/02/20/caching-model-json-with-mongoid-cached-json/">Caching Model JSON with Mongoid-Cached-Json</a></li>
<li><a href="/blog/2012/03/23/simplifying-model-level-json-versioning-with-mongoid-cached-json/">Simplifying Model Level Versioning with Mongoid-Cched-Json</a></li>
<li><a href="/blog/2012/05/30/restful-api-caching-with-garner/">RESTful API Caching with Garner</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
